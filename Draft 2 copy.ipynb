{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for reproducibility\n",
    "import random\n",
    "import tensorflow as tf\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load the dataset\n",
    "train_data = pd.read_csv('sign_mnist_train.csv')\n",
    "test_data = pd.read_csv('sign_mnist_test.csv')\n",
    "\n",
    "# Extract labels and images\n",
    "X_train = train_data.iloc[:, 1:].values\n",
    "y_train = train_data.iloc[:, 0].values\n",
    "X_test = test_data.iloc[:, 1:].values\n",
    "y_test = test_data.iloc[:, 0].values\n",
    "\n",
    "# Remove 'J' (label 9) and 'Z' (label 25)\n",
    "valid_labels = [i for i in range(26) if i not in [9, 25]]\n",
    "train_mask = np.isin(y_train, valid_labels)\n",
    "test_mask = np.isin(y_test, valid_labels)\n",
    "\n",
    "X_train = X_train[train_mask]\n",
    "y_train = y_train[train_mask]\n",
    "X_test = X_test[test_mask]\n",
    "y_test = y_test[test_mask]\n",
    "\n",
    "# Adjust labels to be in range 0-23 instead of 0-24\n",
    "y_train = [i if i < 9 else i - 1 for i in y_train]\n",
    "y_test = [i if i < 9 else i - 1 for i in y_test]\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Reshape images to 32x32 (since the images consists of 32x32 pixels)\n",
    "X_train = X_train.reshape(-1, 32, 32, 1)\n",
    "X_test = X_test.reshape(-1, 32, 32, 1)\n",
    "\n",
    "# Normalize pixel values\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# Create a fixed validation set and a test set from the testing data\n",
    "X_val, X_final_test, y_val, y_final_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "# One-hot encode labels\n",
    "y_train_enc = to_categorical(y_train, num_classes=24)\n",
    "y_val_enc = to_categorical(y_val, num_classes=24)\n",
    "y_final_test_enc = to_categorical(y_final_test, num_classes=24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27455, 32, 32, 1)\n",
      "(7172, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "# Let's see how big it is\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "n_total = X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\linhn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.2827 - loss: 2.3754 - val_accuracy: 0.5700 - val_loss: 1.3219\n",
      "Epoch 2/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6973 - loss: 0.9249 - val_accuracy: 0.7100 - val_loss: 0.9362\n",
      "Epoch 3/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8297 - loss: 0.5159 - val_accuracy: 0.7334 - val_loss: 0.9279\n",
      "Epoch 4/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9095 - loss: 0.2890 - val_accuracy: 0.7437 - val_loss: 0.9216\n",
      "Epoch 5/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9410 - loss: 0.1866 - val_accuracy: 0.7474 - val_loss: 1.0296\n",
      "Epoch 6/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9664 - loss: 0.1147 - val_accuracy: 0.7579 - val_loss: 1.0527\n",
      "Epoch 7/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9607 - loss: 0.1248 - val_accuracy: 0.7697 - val_loss: 1.0137\n",
      "Epoch 8/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9728 - loss: 0.0879 - val_accuracy: 0.7948 - val_loss: 0.9891\n",
      "Epoch 9/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9775 - loss: 0.0758 - val_accuracy: 0.8221 - val_loss: 0.8802\n",
      "Epoch 10/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9859 - loss: 0.0463 - val_accuracy: 0.6196 - val_loss: 2.2188\n",
      "Epoch 11/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9666 - loss: 0.1162 - val_accuracy: 0.7044 - val_loss: 1.5630\n",
      "Epoch 12/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9554 - loss: 0.1372 - val_accuracy: 0.8176 - val_loss: 0.9782\n",
      "Epoch 13/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.8254 - val_loss: 1.0132\n",
      "Epoch 14/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9982 - loss: 0.0082 - val_accuracy: 0.7571 - val_loss: 0.9372\n",
      "Epoch 15/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9855 - loss: 0.0496 - val_accuracy: 0.7967 - val_loss: 0.8653\n",
      "Epoch 16/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 0.0082 - val_accuracy: 0.8288 - val_loss: 0.8663\n",
      "Epoch 17/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0265 - val_accuracy: 0.7434 - val_loss: 1.1830\n",
      "Epoch 18/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9970 - loss: 0.0154 - val_accuracy: 0.8299 - val_loss: 0.8925\n",
      "Epoch 19/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9844 - loss: 0.0526 - val_accuracy: 0.8246 - val_loss: 0.8427\n",
      "Epoch 20/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0037 - val_accuracy: 0.8363 - val_loss: 0.8788\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "# Define the densely connected model\n",
    "dense_model = Sequential([\n",
    "    Flatten(input_shape=(32, 32, 1)),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(24, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "dense_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history_dense = dense_model.fit(X_train, y_train_enc, epochs=20, validation_data=(X_val, y_val_enc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\linhn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5546 - loss: 1.5292 - val_accuracy: 0.8698 - val_loss: 0.4466\n",
      "Epoch 2/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9949 - loss: 0.0373 - val_accuracy: 0.8859 - val_loss: 0.4554\n",
      "Epoch 3/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9984 - loss: 0.0083 - val_accuracy: 0.8751 - val_loss: 0.5138\n",
      "Epoch 4/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.8946 - val_loss: 0.5011\n",
      "Epoch 5/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.2028e-04 - val_accuracy: 0.8988 - val_loss: 0.5283\n",
      "Epoch 6/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.7991e-04 - val_accuracy: 0.9007 - val_loss: 0.5485\n",
      "Epoch 7/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.7101e-04 - val_accuracy: 0.9013 - val_loss: 0.5693\n",
      "Epoch 8/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.0753e-04 - val_accuracy: 0.9010 - val_loss: 0.5920\n",
      "Epoch 9/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.7926e-05 - val_accuracy: 0.9004 - val_loss: 0.6160\n",
      "Epoch 10/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.2782e-05 - val_accuracy: 0.8993 - val_loss: 0.6400\n",
      "Epoch 11/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.6911e-05 - val_accuracy: 0.8996 - val_loss: 0.6646\n",
      "Epoch 12/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.6819e-05 - val_accuracy: 0.9004 - val_loss: 0.6898\n",
      "Epoch 13/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.0468e-05 - val_accuracy: 0.8999 - val_loss: 0.7142\n",
      "Epoch 14/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.4847e-06 - val_accuracy: 0.8996 - val_loss: 0.7401\n",
      "Epoch 15/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.0222e-06 - val_accuracy: 0.8991 - val_loss: 0.7662\n",
      "Epoch 16/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.4864e-06 - val_accuracy: 0.8985 - val_loss: 0.7913\n",
      "Epoch 17/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.5469e-06 - val_accuracy: 0.8985 - val_loss: 0.8169\n",
      "Epoch 18/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.5671e-07 - val_accuracy: 0.8971 - val_loss: 0.8445\n",
      "Epoch 19/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.9881e-07 - val_accuracy: 0.8960 - val_loss: 0.8691\n",
      "Epoch 20/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 3.7398e-07 - val_accuracy: 0.8957 - val_loss: 0.8947\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Define the CNN model\n",
    "cnn_model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(24, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history_cnn = cnn_model.fit(X_train, y_train_enc, epochs=20, validation_data=(X_val, y_val_enc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def evaluate_model(name, model_name, X_final_test, y_final_test_enc, verbose = 2):\n",
    "    model_eval = model_name.evaluate(X_final_test, y_final_test_enc, verbose = verbose)\n",
    "    print(f\"{name} Model - Test Accuracy: {model_eval[1]}\")\n",
    "\n",
    "    # Detailed evaluation of the model\n",
    "    y_pred = np.argmax(model_name.predict(X_final_test), axis=1)\n",
    "\n",
    "    # Compute accuracy per class, skipping index 9 (for J)\n",
    "    accuracy_per_class = []\n",
    "    for i in range(24):\n",
    "        if np.sum(y_final_test == i) > 0:\n",
    "            accuracy_per_class.append(np.mean(y_pred[y_final_test == i] == i))\n",
    "        else:\n",
    "            accuracy_per_class.append(np.nan)  # Handle classes with no samples\n",
    "\n",
    "    # Filter out NaN values to calculate the median accuracy\n",
    "    valid_accuracies = [acc for acc in accuracy_per_class if not np.isnan(acc)]\n",
    "    median_accuracy = np.median(valid_accuracies)\n",
    "\n",
    "    print(f\"Unbiased Median Accuracy: {median_accuracy}\")\n",
    "\n",
    "    # Identify the letter with the highest individual accuracy\n",
    "    highest_accuracy_class = np.nanargmax(accuracy_per_class)\n",
    "    print(f\"Letter with Highest Accuracy: {chr(highest_accuracy_class + ord('A'))}\")\n",
    "\n",
    "    # Identify the letter with the lowest individual accuracy\n",
    "    lowest_accuracy_class = np.nanargmin(accuracy_per_class)\n",
    "    print(f\"Letter with Lowest Accuracy: {chr(lowest_accuracy_class + ord('A'))}\")\n",
    "\n",
    "    # Calculate the confusion matrix\n",
    "  \n",
    "    conf_matrix = confusion_matrix(y_final_test, y_pred)\n",
    "\n",
    "    # Set the diagonal elements to zero to exclude correct classifications\n",
    "    np.fill_diagonal(conf_matrix, 0)\n",
    "\n",
    "    # Find the indices of the top three errors\n",
    "    errors = np.unravel_index(np.argsort(-conf_matrix, axis=None), conf_matrix.shape)\n",
    "\n",
    "    # Get the top three most common errors\n",
    "    common_errors = [(chr(errors[0][i] + ord('A')), chr(errors[1][i] + ord('A'))) for i in range(3)]\n",
    "    print(f\"Most Common Errors: {common_errors}\")\n",
    "\n",
    "    # Report overall mean accuracy and accuracy per letter\n",
    "    mean_accuracy = np.nanmean(accuracy_per_class)\n",
    "    print(f\"Overall Mean Accuracy: {mean_accuracy}\")\n",
    "\n",
    "    # Print each letter and its accuracy\n",
    "    letters = [chr(i + ord('A')) for i in range(26) if i not in [9, 25]]\n",
    "    for i, acc in enumerate(accuracy_per_class):\n",
    "        print(f\"Letter {letters[i]}: Accuracy {acc}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 0s - 4ms/step - accuracy: 0.8363 - loss: 0.8788\n",
      "Dense Model - Test Accuracy: 0.8363078832626343\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "Unbiased Median Accuracy: 0.03864824495892457\n",
      "Letter with Highest Accuracy: B\n",
      "Letter with Lowest Accuracy: K\n",
      "Most Common Errors: [('H', 'U'), ('C', 'E'), ('E', 'K')]\n",
      "Overall Mean Accuracy: 0.04228168717173333\n",
      "Letter A: Accuracy 0.06707317073170732\n",
      "Letter B: Accuracy 0.07692307692307693\n",
      "Letter C: Accuracy 0.019736842105263157\n",
      "Letter D: Accuracy 0.023255813953488372\n",
      "Letter E: Accuracy 0.051587301587301584\n",
      "Letter F: Accuracy 0.038461538461538464\n",
      "Letter G: Accuracy 0.03125\n",
      "Letter H: Accuracy 0.07511737089201878\n",
      "Letter I: Accuracy 0.06802721088435375\n",
      "Letter K: Accuracy 0.043209876543209874\n",
      "Letter L: Accuracy 0.009523809523809525\n",
      "Letter M: Accuracy 0.07\n",
      "Letter N: Accuracy 0.014184397163120567\n",
      "Letter O: Accuracy 0.03305785123966942\n",
      "Letter P: Accuracy 0.02857142857142857\n",
      "Letter Q: Accuracy 0.02666666666666667\n",
      "Letter R: Accuracy 0.028169014084507043\n",
      "Letter S: Accuracy 0.059322033898305086\n",
      "Letter T: Accuracy 0.015503875968992248\n",
      "Letter U: Accuracy 0.058823529411764705\n",
      "Letter V: Accuracy 0.04918032786885246\n",
      "Letter W: Accuracy 0.038834951456310676\n",
      "Letter X: Accuracy 0.051470588235294115\n",
      "Letter Y: Accuracy 0.03680981595092025\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(\"Dense\",dense_model, X_val, y_val_enc, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 1s - 5ms/step - accuracy: 0.8957 - loss: 0.8947\n",
      "CNN Model - Test Accuracy: 0.89570552110672\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "Unbiased Median Accuracy: 0.04366376180101671\n",
      "Letter with Highest Accuracy: B\n",
      "Letter with Lowest Accuracy: Q\n",
      "Most Common Errors: [('C', 'E'), ('L', 'H'), ('O', 'E')]\n",
      "Overall Mean Accuracy: 0.03948595416101395\n",
      "Letter A: Accuracy 0.04878048780487805\n",
      "Letter B: Accuracy 0.07692307692307693\n",
      "Letter C: Accuracy 0.013157894736842105\n",
      "Letter D: Accuracy 0.023255813953488372\n",
      "Letter E: Accuracy 0.051587301587301584\n",
      "Letter F: Accuracy 0.038461538461538464\n",
      "Letter G: Accuracy 0.0375\n",
      "Letter H: Accuracy 0.07511737089201878\n",
      "Letter I: Accuracy 0.047619047619047616\n",
      "Letter K: Accuracy 0.043209876543209874\n",
      "Letter L: Accuracy 0.009523809523809525\n",
      "Letter M: Accuracy 0.06\n",
      "Letter N: Accuracy 0.04964539007092199\n",
      "Letter O: Accuracy 0.03305785123966942\n",
      "Letter P: Accuracy 0.02857142857142857\n",
      "Letter Q: Accuracy 0.013333333333333334\n",
      "Letter R: Accuracy 0.0\n",
      "Letter S: Accuracy 0.06779661016949153\n",
      "Letter T: Accuracy 0.0\n",
      "Letter U: Accuracy 0.051470588235294115\n",
      "Letter V: Accuracy 0.04918032786885246\n",
      "Letter W: Accuracy 0.04854368932038835\n",
      "Letter X: Accuracy 0.04411764705882353\n",
      "Letter Y: Accuracy 0.03680981595092025\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(\"CNN\", cnn_model, X_val, y_val_enc, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define the data augmentation generator\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,        # Randomly rotate images by 10 degrees\n",
    "    width_shift_range=0.1,    # Randomly translate images horizontally by 10% of the width\n",
    "    height_shift_range=0.1,   # Randomly translate images vertically by 10% of the height\n",
    "    zoom_range=0.1,           # Randomly zoom images by 10%\n",
    "    horizontal_flip=True      # Randomly flip images horizontally\n",
    ")\n",
    "\n",
    "# Fit the generator to the training data\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "# Early stopping and learning rate reduction callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.00001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def create_dense_model_with_regularization(layer_sizes, learning_rate=0.001, l2_lambda=0.01):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(32, 32, 1)))\n",
    "    for size in layer_sizes:\n",
    "        model.add(Dense(size, activation='relu', kernel_regularizer=l2(l2_lambda)))\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Dense(24, activation='softmax', kernel_regularizer=l2(l2_lambda)))\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def create_cnn_model_with_regularization(conv_layers, dense_layers, learning_rate=0.001, l2_lambda=0.01):\n",
    "    model = Sequential()\n",
    "    for filters, kernel_size in conv_layers:\n",
    "        model.add(Conv2D(filters, kernel_size, activation='relu', padding='same', kernel_regularizer=l2(l2_lambda), input_shape=(32, 32, 1)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "    model.add(Flatten())\n",
    "    for size in dense_layers:\n",
    "        model.add(Dense(size, activation='relu', kernel_regularizer=l2(l2_lambda)))\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Dense(24, activation='softmax', kernel_regularizer=l2(l2_lambda)))\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_best_model(group_name, model_group, X_train, y_train_enc, batch_size = 30):\n",
    "    # Train and evaluate each  model\n",
    "    model_histories = []\n",
    "    for model in model_group:\n",
    "        print(f'Model for {group_name}: {model}')\n",
    "        history = model.fit(\n",
    "            datagen.flow(X_train, y_train_enc, batch_size=batch_size),\n",
    "            steps_per_epoch=len(X_train) // 30,\n",
    "            epochs=50,\n",
    "            validation_data=(X_val, y_val_enc),\n",
    "            callbacks=[early_stopping, reduce_lr],\n",
    "            verbose=1\n",
    "        )\n",
    "        val_accuracy = history.history['val_accuracy'][-1]\n",
    "        model_histories.append((val_accuracy, model))\n",
    "\n",
    "    # Determine the best model based on validation accuracy\n",
    "    best_val_accuracy, best_model = max(model_histories, key=lambda item: item[0])\n",
    "\n",
    "    print(f'The best model is: {best_model} with a validation accuracy of: {best_val_accuracy}')\n",
    "    return model_histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\linhn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Define different dense models to experiment with\n",
    "dense_models = [\n",
    "    create_dense_model_with_regularization([512, 256], learning_rate=0.001),\n",
    "    create_dense_model_with_regularization([1024, 512, 256], learning_rate=0.001),\n",
    "    create_dense_model_with_regularization([1024, 512, 256, 128], learning_rate=0.001)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define different CNN models with regularization to experiment with\n",
    "cnn_models = [\n",
    "    create_cnn_model_with_regularization([(32, (3, 3)), (64, (3, 3))], [128], learning_rate=0.01, l2_lambda=0.01),\n",
    "    create_cnn_model_with_regularization([(32, (3, 3)), (64, (3, 3)), (128, (3, 3))], [100], learning_rate=0.01, l2_lambda=0.01),\n",
    "    create_cnn_model_with_regularization([(32, (3, 3)), (64, (3, 3)), (128, (3, 3)), (256, (3, 3))], [128], learning_rate=0.01, l2_lambda=0.01)\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for Dense: <Sequential name=sequential_18, built=True>\n",
      "Epoch 1/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6722 - loss: 1.3625 - val_accuracy: 0.7635 - val_loss: 1.0916 - learning_rate: 1.0000e-05\n",
      "Epoch 2/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141us/step - accuracy: 0.6667 - loss: 1.3345 - val_accuracy: 0.7641 - val_loss: 1.0913 - learning_rate: 1.0000e-05\n",
      "Epoch 3/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6728 - loss: 1.3636 - val_accuracy: 0.7621 - val_loss: 1.0896 - learning_rate: 1.0000e-05\n",
      "Epoch 4/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135us/step - accuracy: 0.5000 - loss: 1.6283 - val_accuracy: 0.7621 - val_loss: 1.0894 - learning_rate: 1.0000e-05\n",
      "Epoch 5/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6755 - loss: 1.3537 - val_accuracy: 0.7716 - val_loss: 1.0881 - learning_rate: 1.0000e-05\n",
      "Epoch 6/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155us/step - accuracy: 0.8667 - loss: 1.0984 - val_accuracy: 0.7711 - val_loss: 1.0873 - learning_rate: 1.0000e-05\n",
      "Epoch 7/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6766 - loss: 1.3609 - val_accuracy: 0.7783 - val_loss: 1.0762 - learning_rate: 1.0000e-05\n",
      "Epoch 8/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154us/step - accuracy: 0.6000 - loss: 1.4017 - val_accuracy: 0.7766 - val_loss: 1.0765 - learning_rate: 1.0000e-05\n",
      "Epoch 9/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6750 - loss: 1.3488 - val_accuracy: 0.7730 - val_loss: 1.0948 - learning_rate: 1.0000e-05\n",
      "Epoch 10/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139us/step - accuracy: 0.7000 - loss: 1.5517 - val_accuracy: 0.7699 - val_loss: 1.0951 - learning_rate: 1.0000e-05\n",
      "Epoch 11/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6786 - loss: 1.3434 - val_accuracy: 0.7755 - val_loss: 1.0891 - learning_rate: 1.0000e-05\n",
      "Epoch 12/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137us/step - accuracy: 0.6333 - loss: 1.3068 - val_accuracy: 0.7777 - val_loss: 1.0886 - learning_rate: 1.0000e-05\n",
      "Model for Dense: <Sequential name=sequential_19, built=True>\n",
      "Epoch 1/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6012 - loss: 1.5498 - val_accuracy: 0.7103 - val_loss: 1.2646 - learning_rate: 4.0000e-05\n",
      "Epoch 2/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180us/step - accuracy: 0.8667 - loss: 1.1624 - val_accuracy: 0.7105 - val_loss: 1.2657 - learning_rate: 4.0000e-05\n",
      "Epoch 3/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6301 - loss: 1.4506 - val_accuracy: 0.6707 - val_loss: 1.3042 - learning_rate: 4.0000e-05\n",
      "Epoch 4/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176us/step - accuracy: 0.7333 - loss: 1.1357 - val_accuracy: 0.6737 - val_loss: 1.2980 - learning_rate: 4.0000e-05\n",
      "Epoch 5/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6522 - loss: 1.3825 - val_accuracy: 0.7496 - val_loss: 1.1150 - learning_rate: 1.0000e-05\n",
      "Model for Dense: <Sequential name=sequential_20, built=True>\n",
      "Epoch 1/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5508 - loss: 1.6677 - val_accuracy: 0.5725 - val_loss: 1.5622 - learning_rate: 4.0000e-05\n",
      "Epoch 2/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189us/step - accuracy: 0.7667 - loss: 1.2938 - val_accuracy: 0.5831 - val_loss: 1.5553 - learning_rate: 4.0000e-05\n",
      "Epoch 3/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.5856 - loss: 1.5704 - val_accuracy: 0.6378 - val_loss: 1.3629 - learning_rate: 4.0000e-05\n",
      "Epoch 4/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187us/step - accuracy: 0.7000 - loss: 1.1687 - val_accuracy: 0.6347 - val_loss: 1.3672 - learning_rate: 4.0000e-05\n",
      "Epoch 5/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6062 - loss: 1.4922 - val_accuracy: 0.6838 - val_loss: 1.2655 - learning_rate: 4.0000e-05\n",
      "The best model is: <Sequential name=sequential_18, built=True> with a validation accuracy of: 0.7777467966079712\n"
     ]
    }
   ],
   "source": [
    "dense_histories = return_best_model(\"Dense\", dense_models, X_train, y_train_enc, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for CNN: <Sequential name=sequential_18, built=True>\n",
      "Epoch 1/20\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6948 - loss: 1.2979 - val_accuracy: 0.7836 - val_loss: 1.0618 - learning_rate: 1.0000e-05\n",
      "Epoch 2/20\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142us/step - accuracy: 0.6000 - loss: 1.7159 - val_accuracy: 0.7844 - val_loss: 1.0616 - learning_rate: 1.0000e-05\n",
      "Epoch 3/20\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.7032 - loss: 1.2888 - val_accuracy: 0.7830 - val_loss: 1.0482 - learning_rate: 1.0000e-05\n",
      "Epoch 4/20\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141us/step - accuracy: 0.6667 - loss: 1.3047 - val_accuracy: 0.7842 - val_loss: 1.0474 - learning_rate: 1.0000e-05\n",
      "Epoch 5/20\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.7030 - loss: 1.2830 - val_accuracy: 0.7962 - val_loss: 1.0308 - learning_rate: 1.0000e-05\n",
      "Model for CNN: <Sequential name=sequential_19, built=True>\n",
      "Epoch 1/20\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6674 - loss: 1.3531 - val_accuracy: 0.7348 - val_loss: 1.1091 - learning_rate: 1.0000e-05\n",
      "Epoch 2/20\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 174us/step - accuracy: 0.7333 - loss: 1.1661 - val_accuracy: 0.7365 - val_loss: 1.1070 - learning_rate: 1.0000e-05\n",
      "Epoch 3/20\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6668 - loss: 1.3354 - val_accuracy: 0.7566 - val_loss: 1.0995 - learning_rate: 1.0000e-05\n",
      "Epoch 4/20\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180us/step - accuracy: 0.6333 - loss: 1.2956 - val_accuracy: 0.7546 - val_loss: 1.0972 - learning_rate: 1.0000e-05\n",
      "Epoch 5/20\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6842 - loss: 1.3001 - val_accuracy: 0.6849 - val_loss: 1.2488 - learning_rate: 1.0000e-05\n",
      "Model for CNN: <Sequential name=sequential_20, built=True>\n",
      "Epoch 1/20\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6150 - loss: 1.4863 - val_accuracy: 0.7170 - val_loss: 1.1796 - learning_rate: 1.0000e-05\n",
      "Epoch 2/20\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187us/step - accuracy: 0.5667 - loss: 1.7034 - val_accuracy: 0.7192 - val_loss: 1.1788 - learning_rate: 1.0000e-05\n",
      "Epoch 3/20\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6246 - loss: 1.4474 - val_accuracy: 0.7195 - val_loss: 1.1561 - learning_rate: 1.0000e-05\n",
      "Epoch 4/20\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189us/step - accuracy: 0.7667 - loss: 1.1369 - val_accuracy: 0.7200 - val_loss: 1.1554 - learning_rate: 1.0000e-05\n",
      "Epoch 5/20\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.6410 - loss: 1.4159 - val_accuracy: 0.7334 - val_loss: 1.1161 - learning_rate: 1.0000e-05\n",
      "The best model is: <Sequential name=sequential_18, built=True> with a validation accuracy of: 0.7961516976356506\n"
     ]
    }
   ],
   "source": [
    "cnn_histories = return_best_model(\"CNN\", dense_models, X_train, y_train_enc, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: <Sequential name=sequential_18, built=True> - Final Test Accuracy: 0.7824874520301819\n"
     ]
    }
   ],
   "source": [
    "# Combine all histories and models\n",
    "all_histories = dense_histories + cnn_histories\n",
    "\n",
    "# Select the best model based on validation accuracy\n",
    "best_model = max(all_histories, key=lambda x: x[0])[1]\n",
    "\n",
    "\n",
    "# Evaluate the best model on the final test set\n",
    "final_eval = best_model.evaluate(X_final_test, y_final_test_enc, verbose=0)\n",
    "print(f\"Best Model: {best_model} - Final Test Accuracy: {final_eval[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 0s - 1ms/step - accuracy: 0.7825 - loss: 1.0718\n",
      "CNN Model - Test Accuracy: 0.7824874520301819\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step\n",
      "Unbiased Median Accuracy: 0.8240384615384615\n",
      "Letter with Highest Accuracy: P\n",
      "Letter with Lowest Accuracy: Q\n",
      "Most Common Errors: [('E', 'L'), ('L', 'M'), ('I', 'A')]\n",
      "Overall Mean Accuracy: 0.7812272658392887\n",
      "Letter A: Accuracy 0.7926829268292683\n",
      "Letter B: Accuracy 0.8778280542986425\n",
      "Letter C: Accuracy 0.8618421052631579\n",
      "Letter D: Accuracy 0.6744186046511628\n",
      "Letter E: Accuracy 0.6309523809523809\n",
      "Letter F: Accuracy 0.823076923076923\n",
      "Letter G: Accuracy 0.825\n",
      "Letter H: Accuracy 0.9342723004694836\n",
      "Letter I: Accuracy 0.6258503401360545\n",
      "Letter K: Accuracy 0.6728395061728395\n",
      "Letter L: Accuracy 0.9809523809523809\n",
      "Letter M: Accuracy 0.575\n",
      "Letter N: Accuracy 0.9645390070921985\n",
      "Letter O: Accuracy 0.9008264462809917\n",
      "Letter P: Accuracy 0.9714285714285714\n",
      "Letter Q: Accuracy 0.9866666666666667\n",
      "Letter R: Accuracy 0.352112676056338\n",
      "Letter S: Accuracy 0.5677966101694916\n",
      "Letter T: Accuracy 0.7054263565891473\n",
      "Letter U: Accuracy 0.6397058823529411\n",
      "Letter V: Accuracy 0.6666666666666666\n",
      "Letter W: Accuracy 0.8446601941747572\n",
      "Letter X: Accuracy 0.9485294117647058\n",
      "Letter Y: Accuracy 0.9263803680981595\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(\"CNN\", best_model, X_final_test, y_final_test_enc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

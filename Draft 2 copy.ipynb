{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for reproducibility\n",
    "import random\n",
    "import tensorflow as tf\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load the dataset\n",
    "train_data = pd.read_csv('sign_mnist_train.csv')\n",
    "test_data = pd.read_csv('sign_mnist_test.csv')\n",
    "\n",
    "# Extract labels and images\n",
    "X_train = train_data.iloc[:, 1:].values\n",
    "y_train = train_data.iloc[:, 0].values\n",
    "X_test = test_data.iloc[:, 1:].values\n",
    "y_test = test_data.iloc[:, 0].values\n",
    "\n",
    "# Remove 'J' (label 9) and 'Z' (label 25)\n",
    "valid_labels = [i for i in range(26) if i not in [9, 25]]\n",
    "train_mask = np.isin(y_train, valid_labels)\n",
    "test_mask = np.isin(y_test, valid_labels)\n",
    "\n",
    "X_train = X_train[train_mask]\n",
    "y_train = y_train[train_mask]\n",
    "X_test = X_test[test_mask]\n",
    "y_test = y_test[test_mask]\n",
    "\n",
    "# Adjust labels to be in range 0-23 instead of 0-24\n",
    "y_train = [i if i < 9 else i - 1 for i in y_train]\n",
    "y_test = [i if i < 9 else i - 1 for i in y_test]\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Reshape images to 32x32 (since the images consists of 32x32 pixels)\n",
    "X_train = X_train.reshape(-1, 32, 32, 1)\n",
    "X_test = X_test.reshape(-1, 32, 32, 1)\n",
    "\n",
    "# Normalize pixel values\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# Create a fixed validation set and a test set from the testing data\n",
    "X_val, X_final_test, y_val, y_final_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "# One-hot encode labels\n",
    "y_train_enc = to_categorical(y_train, num_classes=24)\n",
    "y_val_enc = to_categorical(y_val, num_classes=24)\n",
    "y_final_test_enc = to_categorical(y_final_test, num_classes=24)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27455, 32, 32, 1)\n",
      "(7172, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "# Let's see how big it is\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "n_total = X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\linhn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.2827 - loss: 2.3754 - val_accuracy: 0.5700 - val_loss: 1.3219\n",
      "Epoch 2/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6973 - loss: 0.9249 - val_accuracy: 0.7100 - val_loss: 0.9362\n",
      "Epoch 3/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8297 - loss: 0.5159 - val_accuracy: 0.7334 - val_loss: 0.9279\n",
      "Epoch 4/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9095 - loss: 0.2890 - val_accuracy: 0.7437 - val_loss: 0.9216\n",
      "Epoch 5/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9410 - loss: 0.1866 - val_accuracy: 0.7474 - val_loss: 1.0296\n",
      "Epoch 6/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9664 - loss: 0.1147 - val_accuracy: 0.7579 - val_loss: 1.0527\n",
      "Epoch 7/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9607 - loss: 0.1248 - val_accuracy: 0.7697 - val_loss: 1.0137\n",
      "Epoch 8/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9728 - loss: 0.0879 - val_accuracy: 0.7948 - val_loss: 0.9891\n",
      "Epoch 9/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9775 - loss: 0.0758 - val_accuracy: 0.8221 - val_loss: 0.8802\n",
      "Epoch 10/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9859 - loss: 0.0463 - val_accuracy: 0.6196 - val_loss: 2.2188\n",
      "Epoch 11/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9666 - loss: 0.1162 - val_accuracy: 0.7044 - val_loss: 1.5630\n",
      "Epoch 12/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9554 - loss: 0.1372 - val_accuracy: 0.8176 - val_loss: 0.9782\n",
      "Epoch 13/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.8254 - val_loss: 1.0132\n",
      "Epoch 14/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9982 - loss: 0.0082 - val_accuracy: 0.7571 - val_loss: 0.9372\n",
      "Epoch 15/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9855 - loss: 0.0496 - val_accuracy: 0.7967 - val_loss: 0.8653\n",
      "Epoch 16/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9992 - loss: 0.0082 - val_accuracy: 0.8288 - val_loss: 0.8663\n",
      "Epoch 17/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9930 - loss: 0.0265 - val_accuracy: 0.7434 - val_loss: 1.1830\n",
      "Epoch 18/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9970 - loss: 0.0154 - val_accuracy: 0.8299 - val_loss: 0.8925\n",
      "Epoch 19/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9844 - loss: 0.0526 - val_accuracy: 0.8246 - val_loss: 0.8427\n",
      "Epoch 20/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9998 - loss: 0.0037 - val_accuracy: 0.8363 - val_loss: 0.8788\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "# Define the densely connected model\n",
    "dense_model = Sequential([\n",
    "    Flatten(input_shape=(32, 32, 1)),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(24, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "dense_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history_dense = dense_model.fit(X_train, y_train_enc, epochs=20, validation_data=(X_val, y_val_enc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\linhn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5546 - loss: 1.5292 - val_accuracy: 0.8698 - val_loss: 0.4466\n",
      "Epoch 2/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9949 - loss: 0.0373 - val_accuracy: 0.8859 - val_loss: 0.4554\n",
      "Epoch 3/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9984 - loss: 0.0083 - val_accuracy: 0.8751 - val_loss: 0.5138\n",
      "Epoch 4/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.8946 - val_loss: 0.5011\n",
      "Epoch 5/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.2028e-04 - val_accuracy: 0.8988 - val_loss: 0.5283\n",
      "Epoch 6/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.7991e-04 - val_accuracy: 0.9007 - val_loss: 0.5485\n",
      "Epoch 7/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.7101e-04 - val_accuracy: 0.9013 - val_loss: 0.5693\n",
      "Epoch 8/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.0753e-04 - val_accuracy: 0.9010 - val_loss: 0.5920\n",
      "Epoch 9/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.7926e-05 - val_accuracy: 0.9004 - val_loss: 0.6160\n",
      "Epoch 10/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.2782e-05 - val_accuracy: 0.8993 - val_loss: 0.6400\n",
      "Epoch 11/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.6911e-05 - val_accuracy: 0.8996 - val_loss: 0.6646\n",
      "Epoch 12/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.6819e-05 - val_accuracy: 0.9004 - val_loss: 0.6898\n",
      "Epoch 13/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.0468e-05 - val_accuracy: 0.8999 - val_loss: 0.7142\n",
      "Epoch 14/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.4847e-06 - val_accuracy: 0.8996 - val_loss: 0.7401\n",
      "Epoch 15/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.0222e-06 - val_accuracy: 0.8991 - val_loss: 0.7662\n",
      "Epoch 16/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.4864e-06 - val_accuracy: 0.8985 - val_loss: 0.7913\n",
      "Epoch 17/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.5469e-06 - val_accuracy: 0.8985 - val_loss: 0.8169\n",
      "Epoch 18/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 9.5671e-07 - val_accuracy: 0.8971 - val_loss: 0.8445\n",
      "Epoch 19/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 5.9881e-07 - val_accuracy: 0.8960 - val_loss: 0.8691\n",
      "Epoch 20/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 3.7398e-07 - val_accuracy: 0.8957 - val_loss: 0.8947\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Define the CNN model\n",
    "cnn_model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(24, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history_cnn = cnn_model.fit(X_train, y_train_enc, epochs=20, validation_data=(X_val, y_val_enc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def evaluate_model(name, model_name, X_final_test, y_final_test_enc, verbose = 2):\n",
    "    model_eval = model_name.evaluate(X_final_test, y_final_test_enc, verbose = verbose)\n",
    "    print(f\"{name} Model - Test Accuracy: {model_eval[1]}\")\n",
    "\n",
    "    # Detailed evaluation of the model\n",
    "    y_pred = np.argmax(model_name.predict(X_final_test), axis=1)\n",
    "\n",
    "    # Compute accuracy per class, skipping index 9 (for J)\n",
    "    accuracy_per_class = []\n",
    "    for i in range(24):\n",
    "        if np.sum(y_final_test == i) > 0:\n",
    "            accuracy_per_class.append(np.mean(y_pred[y_final_test == i] == i))\n",
    "        else:\n",
    "            accuracy_per_class.append(np.nan)  # Handle classes with no samples\n",
    "\n",
    "    # Filter out NaN values to calculate the median accuracy\n",
    "    valid_accuracies = [acc for acc in accuracy_per_class if not np.isnan(acc)]\n",
    "    median_accuracy = np.median(valid_accuracies)\n",
    "\n",
    "    print(f\"Unbiased Median Accuracy: {median_accuracy}\")\n",
    "\n",
    "    # Identify the letter with the highest individual accuracy\n",
    "    highest_accuracy_class = np.nanargmax(accuracy_per_class)\n",
    "    print(f\"Letter with Highest Accuracy: {chr(highest_accuracy_class + ord('A'))}\")\n",
    "\n",
    "    # Identify the letter with the lowest individual accuracy\n",
    "    lowest_accuracy_class = np.nanargmin(accuracy_per_class)\n",
    "    print(f\"Letter with Lowest Accuracy: {chr(lowest_accuracy_class + ord('A'))}\")\n",
    "\n",
    "    # Calculate the confusion matrix\n",
    "  \n",
    "    conf_matrix = confusion_matrix(y_final_test, y_pred)\n",
    "\n",
    "    # Set the diagonal elements to zero to exclude correct classifications\n",
    "    np.fill_diagonal(conf_matrix, 0)\n",
    "\n",
    "    # Find the indices of the top three errors\n",
    "    errors = np.unravel_index(np.argsort(-conf_matrix, axis=None), conf_matrix.shape)\n",
    "\n",
    "    # Get the top three most common errors\n",
    "    common_errors = [(chr(errors[0][i] + ord('A')), chr(errors[1][i] + ord('A'))) for i in range(3)]\n",
    "    print(f\"Most Common Errors: {common_errors}\")\n",
    "\n",
    "    # Report overall mean accuracy and accuracy per letter\n",
    "    mean_accuracy = np.nanmean(accuracy_per_class)\n",
    "    print(f\"Overall Mean Accuracy: {mean_accuracy}\")\n",
    "\n",
    "    # Print each letter and its accuracy\n",
    "    letters = [chr(i + ord('A')) for i in range(26) if i not in [9, 25]]\n",
    "    for i, acc in enumerate(accuracy_per_class):\n",
    "        print(f\"Letter {letters[i]}: Accuracy {acc}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 0s - 4ms/step - accuracy: 0.8363 - loss: 0.8788\n",
      "Dense Model - Test Accuracy: 0.8363078832626343\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
      "Unbiased Median Accuracy: 0.03864824495892457\n",
      "Letter with Highest Accuracy: B\n",
      "Letter with Lowest Accuracy: K\n",
      "Most Common Errors: [('H', 'U'), ('C', 'E'), ('E', 'K')]\n",
      "Overall Mean Accuracy: 0.04228168717173333\n",
      "Letter A: Accuracy 0.06707317073170732\n",
      "Letter B: Accuracy 0.07692307692307693\n",
      "Letter C: Accuracy 0.019736842105263157\n",
      "Letter D: Accuracy 0.023255813953488372\n",
      "Letter E: Accuracy 0.051587301587301584\n",
      "Letter F: Accuracy 0.038461538461538464\n",
      "Letter G: Accuracy 0.03125\n",
      "Letter H: Accuracy 0.07511737089201878\n",
      "Letter I: Accuracy 0.06802721088435375\n",
      "Letter K: Accuracy 0.043209876543209874\n",
      "Letter L: Accuracy 0.009523809523809525\n",
      "Letter M: Accuracy 0.07\n",
      "Letter N: Accuracy 0.014184397163120567\n",
      "Letter O: Accuracy 0.03305785123966942\n",
      "Letter P: Accuracy 0.02857142857142857\n",
      "Letter Q: Accuracy 0.02666666666666667\n",
      "Letter R: Accuracy 0.028169014084507043\n",
      "Letter S: Accuracy 0.059322033898305086\n",
      "Letter T: Accuracy 0.015503875968992248\n",
      "Letter U: Accuracy 0.058823529411764705\n",
      "Letter V: Accuracy 0.04918032786885246\n",
      "Letter W: Accuracy 0.038834951456310676\n",
      "Letter X: Accuracy 0.051470588235294115\n",
      "Letter Y: Accuracy 0.03680981595092025\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(\"Dense\",dense_model, X_val, y_val_enc, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 1s - 5ms/step - accuracy: 0.8957 - loss: 0.8947\n",
      "CNN Model - Test Accuracy: 0.89570552110672\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
      "Unbiased Median Accuracy: 0.04366376180101671\n",
      "Letter with Highest Accuracy: B\n",
      "Letter with Lowest Accuracy: Q\n",
      "Most Common Errors: [('C', 'E'), ('L', 'H'), ('O', 'E')]\n",
      "Overall Mean Accuracy: 0.03948595416101395\n",
      "Letter A: Accuracy 0.04878048780487805\n",
      "Letter B: Accuracy 0.07692307692307693\n",
      "Letter C: Accuracy 0.013157894736842105\n",
      "Letter D: Accuracy 0.023255813953488372\n",
      "Letter E: Accuracy 0.051587301587301584\n",
      "Letter F: Accuracy 0.038461538461538464\n",
      "Letter G: Accuracy 0.0375\n",
      "Letter H: Accuracy 0.07511737089201878\n",
      "Letter I: Accuracy 0.047619047619047616\n",
      "Letter K: Accuracy 0.043209876543209874\n",
      "Letter L: Accuracy 0.009523809523809525\n",
      "Letter M: Accuracy 0.06\n",
      "Letter N: Accuracy 0.04964539007092199\n",
      "Letter O: Accuracy 0.03305785123966942\n",
      "Letter P: Accuracy 0.02857142857142857\n",
      "Letter Q: Accuracy 0.013333333333333334\n",
      "Letter R: Accuracy 0.0\n",
      "Letter S: Accuracy 0.06779661016949153\n",
      "Letter T: Accuracy 0.0\n",
      "Letter U: Accuracy 0.051470588235294115\n",
      "Letter V: Accuracy 0.04918032786885246\n",
      "Letter W: Accuracy 0.04854368932038835\n",
      "Letter X: Accuracy 0.04411764705882353\n",
      "Letter Y: Accuracy 0.03680981595092025\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(\"CNN\", cnn_model, X_val, y_val_enc, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define the data augmentation generator\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,        # Randomly rotate images by 10 degrees\n",
    "    width_shift_range=0.1,    # Randomly translate images horizontally by 10% of the width\n",
    "    height_shift_range=0.1,   # Randomly translate images vertically by 10% of the height\n",
    "    zoom_range=0.1,           # Randomly zoom images by 10%\n",
    "    horizontal_flip=True      # Randomly flip images horizontally\n",
    ")\n",
    "\n",
    "# Fit the generator to the training data\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "# Early stopping and learning rate reduction callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.00001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def create_dense_model_with_regularization(layer_sizes, learning_rate=0.001, l2_lambda=0.01):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(32, 32, 1)))\n",
    "    for size in layer_sizes:\n",
    "        model.add(Dense(size, activation='relu', kernel_regularizer=l2(l2_lambda)))\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Dense(24, activation='softmax', kernel_regularizer=l2(l2_lambda)))\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def create_cnn_model_with_regularization(conv_layers, dense_layers, learning_rate=0.001, l2_lambda=0.01):\n",
    "    model = Sequential()\n",
    "    for filters, kernel_size in conv_layers:\n",
    "        model.add(Conv2D(filters, kernel_size, activation='relu', padding='same', kernel_regularizer=l2(l2_lambda), input_shape=(32, 32, 1)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "    model.add(Flatten())\n",
    "    for size in dense_layers:\n",
    "        model.add(Dense(size, activation='relu', kernel_regularizer=l2(l2_lambda)))\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Dense(24, activation='softmax', kernel_regularizer=l2(l2_lambda)))\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_best_model(group_name, model_group, X_train, y_train_enc, batch_size = 30):\n",
    "    # Train and evaluate each  model\n",
    "    model_histories = []\n",
    "    for model in model_group:\n",
    "        print(f'Model for {group_name}: {model}')\n",
    "        history = model.fit(\n",
    "            datagen.flow(X_train, y_train_enc, batch_size=batch_size),\n",
    "            steps_per_epoch=len(X_train) // 30,\n",
    "            epochs=50,\n",
    "            validation_data=(X_val, y_val_enc),\n",
    "            callbacks=[early_stopping, reduce_lr],\n",
    "            verbose=1\n",
    "        )\n",
    "        val_accuracy = history.history['val_accuracy'][-1]\n",
    "        model_histories.append((val_accuracy, model))\n",
    "\n",
    "    # Determine the best model based on validation accuracy\n",
    "    best_val_accuracy, best_model = max(model_histories, key=lambda item: item[0])\n",
    "\n",
    "    print(f'The best model is: {best_model} with a validation accuracy of: {best_val_accuracy}')\n",
    "    return model_histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\linhn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Define different dense models to experiment with\n",
    "dense_models = [\n",
    "    create_dense_model_with_regularization([512, 256], learning_rate=0.001),\n",
    "    create_dense_model_with_regularization([1024, 512, 256], learning_rate=0.001),\n",
    "    create_dense_model_with_regularization([1024, 512, 256, 128], learning_rate=0.001)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\linhn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Define different CNN models with regularization to experiment with\n",
    "cnn_models = [\n",
    "    create_cnn_model_with_regularization([(32, (3, 3)), (64, (3, 3))], [128],learning_rate=0.001),\n",
    "    create_cnn_model_with_regularization([(32, (3, 3)), (64, (3, 3)), (128, (3, 3))], [256], learning_rate=0.001),\n",
    "    create_cnn_model_with_regularization([(32, (3, 3)), (64, (3, 3)), (128, (3, 3)), (256, (3, 3))], [512], learning_rate=0.001)\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for Dense: <Sequential name=sequential_18, built=True>\n",
      "Epoch 1/50\n",
      "\u001b[1m  1/915\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m33:40\u001b[0m 2s/step - accuracy: 0.0333 - loss: 14.2928"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\linhn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.2369 - loss: 6.9747 - val_accuracy: 0.0510 - val_loss: 16.1490 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153us/step - accuracy: 0.4000 - loss: 2.4090 - val_accuracy: 0.0508 - val_loss: 15.3376 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m  1/915\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m42s\u001b[0m 47ms/step - accuracy: 0.3000 - loss: 2.7853"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\linhn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.3815 - loss: 2.4453 - val_accuracy: 0.1065 - val_loss: 5.9742 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135us/step - accuracy: 0.5333 - loss: 1.9002 - val_accuracy: 0.1576 - val_loss: 5.2179 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4153 - loss: 2.2274 - val_accuracy: 0.0739 - val_loss: 7.9362 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133us/step - accuracy: 0.4667 - loss: 1.9804 - val_accuracy: 0.0661 - val_loss: 8.0234 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4434 - loss: 2.1271 - val_accuracy: 0.2315 - val_loss: 3.0373 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136us/step - accuracy: 0.5667 - loss: 1.7423 - val_accuracy: 0.2303 - val_loss: 3.1982 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.4714 - loss: 2.0055 - val_accuracy: 0.2005 - val_loss: 3.3633 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140us/step - accuracy: 0.5667 - loss: 1.9303 - val_accuracy: 0.1899 - val_loss: 3.6571 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5359 - loss: 1.7880 - val_accuracy: 0.3737 - val_loss: 2.3726 - learning_rate: 2.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136us/step - accuracy: 0.6333 - loss: 1.4800 - val_accuracy: 0.3045 - val_loss: 2.6779 - learning_rate: 2.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5700 - loss: 1.6767 - val_accuracy: 0.5142 - val_loss: 1.8011 - learning_rate: 2.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138us/step - accuracy: 0.7333 - loss: 1.4578 - val_accuracy: 0.5226 - val_loss: 1.7755 - learning_rate: 2.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5754 - loss: 1.6394 - val_accuracy: 0.5842 - val_loss: 1.5892 - learning_rate: 2.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136us/step - accuracy: 0.6667 - loss: 1.4360 - val_accuracy: 0.5817 - val_loss: 1.6046 - learning_rate: 2.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5856 - loss: 1.6088 - val_accuracy: 0.5917 - val_loss: 1.5103 - learning_rate: 2.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 135us/step - accuracy: 0.5667 - loss: 1.5278 - val_accuracy: 0.5929 - val_loss: 1.5305 - learning_rate: 2.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6008 - loss: 1.5582 - val_accuracy: 0.5591 - val_loss: 1.6615 - learning_rate: 2.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133us/step - accuracy: 0.6000 - loss: 1.4849 - val_accuracy: 0.5739 - val_loss: 1.6134 - learning_rate: 2.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6196 - loss: 1.5078 - val_accuracy: 0.6944 - val_loss: 1.2599 - learning_rate: 4.0000e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136us/step - accuracy: 0.7333 - loss: 1.4946 - val_accuracy: 0.6972 - val_loss: 1.2556 - learning_rate: 4.0000e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6268 - loss: 1.4903 - val_accuracy: 0.7284 - val_loss: 1.2034 - learning_rate: 4.0000e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136us/step - accuracy: 0.6000 - loss: 1.4611 - val_accuracy: 0.7298 - val_loss: 1.1994 - learning_rate: 4.0000e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6331 - loss: 1.4652 - val_accuracy: 0.7089 - val_loss: 1.2410 - learning_rate: 4.0000e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138us/step - accuracy: 0.6000 - loss: 1.6158 - val_accuracy: 0.7100 - val_loss: 1.2427 - learning_rate: 4.0000e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6379 - loss: 1.4498 - val_accuracy: 0.6514 - val_loss: 1.3497 - learning_rate: 4.0000e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 136us/step - accuracy: 0.7333 - loss: 1.2388 - val_accuracy: 0.6548 - val_loss: 1.3397 - learning_rate: 1.0000e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6443 - loss: 1.4303 - val_accuracy: 0.7532 - val_loss: 1.1530 - learning_rate: 1.0000e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140us/step - accuracy: 0.7333 - loss: 1.2233 - val_accuracy: 0.7535 - val_loss: 1.1530 - learning_rate: 1.0000e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6491 - loss: 1.4256 - val_accuracy: 0.7476 - val_loss: 1.1460 - learning_rate: 1.0000e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139us/step - accuracy: 0.6667 - loss: 1.3173 - val_accuracy: 0.7485 - val_loss: 1.1464 - learning_rate: 1.0000e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6481 - loss: 1.4250 - val_accuracy: 0.7496 - val_loss: 1.1389 - learning_rate: 1.0000e-05\n",
      "Epoch 34/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141us/step - accuracy: 0.5333 - loss: 1.4700 - val_accuracy: 0.7501 - val_loss: 1.1388 - learning_rate: 1.0000e-05\n",
      "Epoch 35/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6465 - loss: 1.4286 - val_accuracy: 0.7474 - val_loss: 1.1675 - learning_rate: 1.0000e-05\n",
      "Epoch 36/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138us/step - accuracy: 0.5000 - loss: 1.6793 - val_accuracy: 0.7471 - val_loss: 1.1675 - learning_rate: 1.0000e-05\n",
      "Epoch 37/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6485 - loss: 1.4261 - val_accuracy: 0.7582 - val_loss: 1.1378 - learning_rate: 1.0000e-05\n",
      "Epoch 38/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139us/step - accuracy: 0.8000 - loss: 1.1765 - val_accuracy: 0.7574 - val_loss: 1.1377 - learning_rate: 1.0000e-05\n",
      "Epoch 39/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6555 - loss: 1.4075 - val_accuracy: 0.7554 - val_loss: 1.1328 - learning_rate: 1.0000e-05\n",
      "Epoch 40/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138us/step - accuracy: 0.6667 - loss: 1.2070 - val_accuracy: 0.7560 - val_loss: 1.1339 - learning_rate: 1.0000e-05\n",
      "Epoch 41/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6614 - loss: 1.3937 - val_accuracy: 0.7655 - val_loss: 1.1309 - learning_rate: 1.0000e-05\n",
      "Epoch 42/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140us/step - accuracy: 0.7333 - loss: 1.1198 - val_accuracy: 0.7655 - val_loss: 1.1307 - learning_rate: 1.0000e-05\n",
      "Epoch 43/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6564 - loss: 1.3961 - val_accuracy: 0.7535 - val_loss: 1.1392 - learning_rate: 1.0000e-05\n",
      "Epoch 44/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140us/step - accuracy: 0.5667 - loss: 1.4490 - val_accuracy: 0.7535 - val_loss: 1.1368 - learning_rate: 1.0000e-05\n",
      "Epoch 45/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6593 - loss: 1.3972 - val_accuracy: 0.7691 - val_loss: 1.1008 - learning_rate: 1.0000e-05\n",
      "Epoch 46/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140us/step - accuracy: 0.5667 - loss: 1.4581 - val_accuracy: 0.7694 - val_loss: 1.1021 - learning_rate: 1.0000e-05\n",
      "Epoch 47/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6583 - loss: 1.4000 - val_accuracy: 0.7674 - val_loss: 1.1119 - learning_rate: 1.0000e-05\n",
      "Epoch 48/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137us/step - accuracy: 0.6667 - loss: 1.3292 - val_accuracy: 0.7674 - val_loss: 1.1124 - learning_rate: 1.0000e-05\n",
      "Epoch 49/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6652 - loss: 1.3869 - val_accuracy: 0.7568 - val_loss: 1.1227 - learning_rate: 1.0000e-05\n",
      "Epoch 50/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137us/step - accuracy: 0.5000 - loss: 1.5943 - val_accuracy: 0.7577 - val_loss: 1.1229 - learning_rate: 1.0000e-05\n",
      "Model for Dense: <Sequential name=sequential_19, built=True>\n",
      "Epoch 1/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.2182 - loss: 10.6483 - val_accuracy: 0.0574 - val_loss: 6.8176 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183us/step - accuracy: 0.2000 - loss: 2.9676 - val_accuracy: 0.0421 - val_loss: 5.6783 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.3228 - loss: 2.7242 - val_accuracy: 0.0284 - val_loss: 15.3208 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 191us/step - accuracy: 0.3667 - loss: 2.4717 - val_accuracy: 0.0332 - val_loss: 15.3812 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.3471 - loss: 2.5561 - val_accuracy: 0.1336 - val_loss: 4.6293 - learning_rate: 0.0010\n",
      "Model for Dense: <Sequential name=sequential_20, built=True>\n",
      "Epoch 1/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.2035 - loss: 12.0869 - val_accuracy: 0.0248 - val_loss: 11.2273 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208us/step - accuracy: 0.3333 - loss: 3.0572 - val_accuracy: 0.0248 - val_loss: 10.3962 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.3048 - loss: 2.8787 - val_accuracy: 0.0912 - val_loss: 5.4180 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225us/step - accuracy: 0.3000 - loss: 2.7927 - val_accuracy: 0.0873 - val_loss: 5.7059 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.3201 - loss: 2.6801 - val_accuracy: 0.0700 - val_loss: 9.5534 - learning_rate: 0.0010\n",
      "The best model is: <Sequential name=sequential_18, built=True> with a validation accuracy of: 0.7576687335968018\n"
     ]
    }
   ],
   "source": [
    "dense_histories = return_best_model(\"Dense\", dense_models, X_train, y_train_enc, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for CNN: <Sequential name=sequential_18, built=True>\n",
      "Epoch 1/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6668 - loss: 1.3747 - val_accuracy: 0.7705 - val_loss: 1.1157 - learning_rate: 1.0000e-05\n",
      "Epoch 2/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 139us/step - accuracy: 0.6333 - loss: 1.4292 - val_accuracy: 0.7722 - val_loss: 1.1150 - learning_rate: 1.0000e-05\n",
      "Epoch 3/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6639 - loss: 1.3817 - val_accuracy: 0.7730 - val_loss: 1.0972 - learning_rate: 1.0000e-05\n",
      "Epoch 4/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142us/step - accuracy: 0.8000 - loss: 1.2854 - val_accuracy: 0.7724 - val_loss: 1.0977 - learning_rate: 1.0000e-05\n",
      "Epoch 5/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6642 - loss: 1.3863 - val_accuracy: 0.7446 - val_loss: 1.1388 - learning_rate: 1.0000e-05\n",
      "Epoch 6/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141us/step - accuracy: 0.8000 - loss: 1.2650 - val_accuracy: 0.7465 - val_loss: 1.1372 - learning_rate: 1.0000e-05\n",
      "Epoch 7/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6656 - loss: 1.3809 - val_accuracy: 0.7780 - val_loss: 1.0981 - learning_rate: 1.0000e-05\n",
      "Epoch 8/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138us/step - accuracy: 0.6000 - loss: 1.4627 - val_accuracy: 0.7769 - val_loss: 1.0988 - learning_rate: 1.0000e-05\n",
      "Model for CNN: <Sequential name=sequential_19, built=True>\n",
      "Epoch 1/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.3100 - loss: 2.8432 - val_accuracy: 0.1205 - val_loss: 4.2274 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182us/step - accuracy: 0.2667 - loss: 2.8251 - val_accuracy: 0.0728 - val_loss: 4.8723 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.3556 - loss: 2.5012 - val_accuracy: 0.0731 - val_loss: 10.5937 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181us/step - accuracy: 0.2667 - loss: 2.5641 - val_accuracy: 0.0655 - val_loss: 10.6806 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.4571 - loss: 2.0896 - val_accuracy: 0.3305 - val_loss: 2.4389 - learning_rate: 2.0000e-04\n",
      "Model for CNN: <Sequential name=sequential_20, built=True>\n",
      "Epoch 1/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.3001 - loss: 2.9748 - val_accuracy: 0.0248 - val_loss: 19.5599 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 198us/step - accuracy: 0.2333 - loss: 2.8475 - val_accuracy: 0.0254 - val_loss: 17.3040 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.3191 - loss: 2.6618 - val_accuracy: 0.0817 - val_loss: 4.2189 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194us/step - accuracy: 0.2333 - loss: 3.0202 - val_accuracy: 0.0968 - val_loss: 4.1331 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.3418 - loss: 2.5090 - val_accuracy: 0.0929 - val_loss: 4.5954 - learning_rate: 0.0010\n",
      "The best model is: <Sequential name=sequential_18, built=True> with a validation accuracy of: 0.7769101858139038\n"
     ]
    }
   ],
   "source": [
    "cnn_histories = return_best_model(\"CNN\", dense_models, X_train, y_train_enc, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: <Sequential name=sequential_18, built=True> - Final Test Accuracy: 0.7640825510025024\n"
     ]
    }
   ],
   "source": [
    "# Combine all histories and models\n",
    "all_histories = dense_histories + cnn_histories\n",
    "\n",
    "# Select the best model based on validation accuracy\n",
    "best_model = max(all_histories, key=lambda x: x[0])[1]\n",
    "\n",
    "\n",
    "# Evaluate the best model on the final test set\n",
    "final_eval = best_model.evaluate(X_final_test, y_final_test_enc, verbose=0)\n",
    "print(f\"Best Model: {best_model} - Final Test Accuracy: {final_eval[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 0s - 1ms/step - accuracy: 0.7641 - loss: 1.1075\n",
      "CNN Model - Test Accuracy: 0.7640825510025024\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Unbiased Median Accuracy: 0.7863119834710743\n",
      "Letter with Highest Accuracy: K\n",
      "Letter with Lowest Accuracy: Q\n",
      "Most Common Errors: [('E', 'R'), ('L', 'R'), ('T', 'U')]\n",
      "Overall Mean Accuracy: 0.7597572908084921\n",
      "Letter A: Accuracy 0.7560975609756098\n",
      "Letter B: Accuracy 0.9230769230769231\n",
      "Letter C: Accuracy 0.9276315789473685\n",
      "Letter D: Accuracy 0.689922480620155\n",
      "Letter E: Accuracy 0.7182539682539683\n",
      "Letter F: Accuracy 0.9153846153846154\n",
      "Letter G: Accuracy 0.7875\n",
      "Letter H: Accuracy 0.7934272300469484\n",
      "Letter I: Accuracy 0.8571428571428571\n",
      "Letter K: Accuracy 0.5987654320987654\n",
      "Letter L: Accuracy 1.0\n",
      "Letter M: Accuracy 0.47\n",
      "Letter N: Accuracy 0.8865248226950354\n",
      "Letter O: Accuracy 0.7851239669421488\n",
      "Letter P: Accuracy 0.9257142857142857\n",
      "Letter Q: Accuracy 0.8533333333333334\n",
      "Letter R: Accuracy 0.36619718309859156\n",
      "Letter S: Accuracy 0.5508474576271186\n",
      "Letter T: Accuracy 0.6744186046511628\n",
      "Letter U: Accuracy 0.5735294117647058\n",
      "Letter V: Accuracy 0.6775956284153005\n",
      "Letter W: Accuracy 0.7281553398058253\n",
      "Letter X: Accuracy 0.9411764705882353\n",
      "Letter Y: Accuracy 0.8343558282208589\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(\"CNN\", best_model, X_final_test, y_final_test_enc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

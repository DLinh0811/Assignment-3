{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for reproducibility\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load the dataset\n",
    "train_data = pd.read_csv('sign_mnist_train.csv')\n",
    "test_data = pd.read_csv('sign_mnist_test.csv')\n",
    "\n",
    "# Extract labels and images\n",
    "X_train = train_data.iloc[:, 1:].values\n",
    "y_train = train_data.iloc[:, 0].values\n",
    "X_test = test_data.iloc[:, 1:].values\n",
    "y_test = test_data.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Adjust labels to be in range 0-23 instead of 0-24\n",
    "y_train = [i if i < 9 else i - 1 for i in y_train]\n",
    "y_test = [i if i < 9 else i - 1 for i in y_test]\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Reshape images to 32x32 (since the images consists of 32x32 pixels)\n",
    "X_train = X_train.reshape(-1, 32, 32, 1)\n",
    "X_test = X_test.reshape(-1, 32, 32, 1)\n",
    "\n",
    "# Normalize pixel values\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "# Create a fixed validation set and a test set from the testing data\n",
    "X_val, X_final_test, y_val, y_final_test = train_test_split(X_test, y_test, stratify= y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "# One-hot encode labels\n",
    "y_train_enc = to_categorical(y_train, num_classes=24)\n",
    "y_val_enc = to_categorical(y_val, num_classes=24)\n",
    "y_final_test_enc = to_categorical(y_final_test, num_classes=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27455, 32, 32, 1)\n",
      "(7172, 32, 32, 1)\n"
     ]
    }
   ],
   "source": [
    "# Let's see how big it is\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "n_total = X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\linhn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.2786 - loss: 2.3831 - val_accuracy: 0.5176 - val_loss: 1.4017\n",
      "Epoch 2/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.6834 - loss: 0.9572 - val_accuracy: 0.6740 - val_loss: 0.9474\n",
      "Epoch 3/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8265 - loss: 0.5239 - val_accuracy: 0.7482 - val_loss: 0.8146\n",
      "Epoch 4/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9114 - loss: 0.2776 - val_accuracy: 0.7535 - val_loss: 0.8278\n",
      "Epoch 5/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9430 - loss: 0.1769 - val_accuracy: 0.7713 - val_loss: 0.8328\n",
      "Epoch 6/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9702 - loss: 0.0997 - val_accuracy: 0.7730 - val_loss: 0.8638\n",
      "Epoch 7/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9847 - loss: 0.0580 - val_accuracy: 0.7989 - val_loss: 0.8484\n",
      "Epoch 8/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9802 - loss: 0.0688 - val_accuracy: 0.7507 - val_loss: 1.0679\n",
      "Epoch 9/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9776 - loss: 0.0743 - val_accuracy: 0.7886 - val_loss: 0.9635\n",
      "Epoch 10/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9966 - loss: 0.0148 - val_accuracy: 0.8249 - val_loss: 0.8168\n",
      "Epoch 11/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.8229 - val_loss: 0.8540\n",
      "Epoch 12/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9696 - loss: 0.1092 - val_accuracy: 0.7998 - val_loss: 0.9419\n",
      "Epoch 13/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9833 - loss: 0.0591 - val_accuracy: 0.8327 - val_loss: 0.7886\n",
      "Epoch 14/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9859 - loss: 0.0467 - val_accuracy: 0.8288 - val_loss: 0.8257\n",
      "Epoch 15/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9999 - loss: 0.0024 - val_accuracy: 0.8268 - val_loss: 0.8556\n",
      "Epoch 16/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0015 - val_accuracy: 0.8274 - val_loss: 0.8732\n",
      "Epoch 17/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9249 - loss: 0.2803 - val_accuracy: 0.8352 - val_loss: 0.7688\n",
      "Epoch 18/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.8263 - val_loss: 0.8184\n",
      "Epoch 19/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9886 - loss: 0.0380 - val_accuracy: 0.8232 - val_loss: 0.7269\n",
      "Epoch 20/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.8288 - val_loss: 0.8294\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "\n",
    "\n",
    "# Define the densely connected model\n",
    "dense_model = Sequential([\n",
    "    Flatten(input_shape=(32, 32, 1)),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(24, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "set_seed(42)\n",
    "dense_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history_dense = dense_model.fit(X_train, y_train_enc, epochs=20, validation_data=(X_val, y_val_enc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\linhn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5623 - loss: 1.5057 - val_accuracy: 0.8795 - val_loss: 0.4001\n",
      "Epoch 2/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9948 - loss: 0.0352 - val_accuracy: 0.9038 - val_loss: 0.3952\n",
      "Epoch 3/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0076 - val_accuracy: 0.9163 - val_loss: 0.3932\n",
      "Epoch 4/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.9200 - val_loss: 0.3761\n",
      "Epoch 5/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.0789e-04 - val_accuracy: 0.9211 - val_loss: 0.3821\n",
      "Epoch 6/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.3329e-04 - val_accuracy: 0.9214 - val_loss: 0.3918\n",
      "Epoch 7/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.4209e-04 - val_accuracy: 0.9208 - val_loss: 0.4043\n",
      "Epoch 8/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.7786e-05 - val_accuracy: 0.9194 - val_loss: 0.4175\n",
      "Epoch 9/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.4422e-05 - val_accuracy: 0.9197 - val_loss: 0.4305\n",
      "Epoch 10/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.3674e-05 - val_accuracy: 0.9194 - val_loss: 0.4465\n",
      "Epoch 11/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.0749e-05 - val_accuracy: 0.9183 - val_loss: 0.4620\n",
      "Epoch 12/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.2772e-05 - val_accuracy: 0.9186 - val_loss: 0.4781\n",
      "Epoch 13/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.9164e-06 - val_accuracy: 0.9169 - val_loss: 0.4961\n",
      "Epoch 14/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.8694e-06 - val_accuracy: 0.9175 - val_loss: 0.5105\n",
      "Epoch 15/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.9861e-06 - val_accuracy: 0.9172 - val_loss: 0.5286\n",
      "Epoch 16/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8445e-06 - val_accuracy: 0.9163 - val_loss: 0.5432\n",
      "Epoch 17/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.1474e-06 - val_accuracy: 0.9177 - val_loss: 0.5600\n",
      "Epoch 18/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.0926e-07 - val_accuracy: 0.9183 - val_loss: 0.5747\n",
      "Epoch 19/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.4490e-07 - val_accuracy: 0.9191 - val_loss: 0.5890\n",
      "Epoch 20/20\n",
      "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.7687e-07 - val_accuracy: 0.9194 - val_loss: 0.6062\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "\n",
    "# Define the CNN model\n",
    "cnn_model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 1)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(24, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "set_seed(42)\n",
    "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history_cnn = cnn_model.fit(X_train, y_train_enc, epochs=20, validation_data=(X_val, y_val_enc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def evaluate_model(name, model_name, X_final_test, y_final_test_enc, verbose = 2):\n",
    "    model_eval = model_name.evaluate(X_final_test, y_final_test_enc, verbose = verbose)\n",
    "    print(f\"{name} Model - Test Accuracy: {model_eval[1]}\")\n",
    "\n",
    "    # Detailed evaluation of the model\n",
    "    y_pred = np.argmax(model_name.predict(X_final_test), axis=1)\n",
    "\n",
    "    # Compute accuracy per class, skipping index 9 (for J)\n",
    "    y_true = np.argmax(y_final_test_enc, axis=1)\n",
    "    accuracy_per_class = []\n",
    "    for i in range(24):\n",
    "        if np.sum(y_true == i) > 0:\n",
    "            accuracy_per_class.append(np.mean(y_pred[y_true == i] == i))\n",
    "        else:\n",
    "            accuracy_per_class.append(np.nan)  # Handle classes with no samples\n",
    "\n",
    "    # Filter out NaN values to calculate the median accuracy\n",
    "    valid_accuracies = [acc for acc in accuracy_per_class if not np.isnan(acc)]\n",
    "    median_accuracy = np.median(valid_accuracies)\n",
    "\n",
    "    print(f\"Unbiased Median Accuracy: {median_accuracy}\")\n",
    "\n",
    "    # Identify the letter with the highest individual accuracy\n",
    "    highest_accuracy_class = np.nanargmax(accuracy_per_class)\n",
    "    print(f\"Letter with Highest Accuracy: {chr(highest_accuracy_class + ord('A'))}\")\n",
    "\n",
    "    # Identify the letter with the lowest individual accuracy\n",
    "    lowest_accuracy_class = np.nanargmin(accuracy_per_class)\n",
    "    print(f\"Letter with Lowest Accuracy: {chr(lowest_accuracy_class + ord('A'))}\")\n",
    "\n",
    "    # Calculate the confusion matrix\n",
    "  \n",
    "    conf_matrix = confusion_matrix(y_final_test, y_pred)\n",
    "\n",
    "    # Set the diagonal elements to zero to exclude correct classifications\n",
    "    np.fill_diagonal(conf_matrix, 0)\n",
    "\n",
    "    # Find the indices of the top three errors\n",
    "    errors = np.unravel_index(np.argsort(-conf_matrix, axis=None), conf_matrix.shape)\n",
    "\n",
    "    # Get the top three most common errors\n",
    "    common_errors = [(chr(errors[0][i] + ord('A')), chr(errors[1][i] + ord('A'))) for i in range(3)]\n",
    "    print(f\"Most Common Errors: {common_errors}\")\n",
    "\n",
    "    # Report overall mean accuracy and accuracy per letter\n",
    "    mean_accuracy = np.nanmean(accuracy_per_class)\n",
    "    print(f\"Overall Mean Accuracy: {mean_accuracy}\")\n",
    "\n",
    "    # Print each letter and its accuracy\n",
    "    letters = [chr(i + ord('A')) for i in range(26) if i not in [9, 25]]\n",
    "    for i, acc in enumerate(accuracy_per_class):\n",
    "        print(f\"Letter {letters[i]}: Accuracy {acc}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define the data augmentation generator\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,        # Randomly rotate images by 10 degrees\n",
    "    width_shift_range=0.1,    # Randomly translate images horizontally by 10% of the width\n",
    "    height_shift_range=0.1,   # Randomly translate images vertically by 10% of the height\n",
    "    zoom_range=0.1,           # Randomly zoom images by 10%\n",
    "    horizontal_flip=True      # Randomly flip images horizontally\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "# Early stopping and learning rate reduction callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.00001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "def create_dense_model_with_regularization(layer_sizes, learning_rate=0.001, l2_lambda=0.01):\n",
    "    set_seed(42)\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(32, 32, 1)))\n",
    "    for size in layer_sizes:\n",
    "        model.add(Dense(size, activation='relu', kernel_regularizer=l2(l2_lambda)))\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Dense(24, activation='softmax', kernel_regularizer=l2(l2_lambda)))\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow import keras\n",
    "\n",
    "# def create_cnn_model_with_regularization(conv_layers, dense_layers, learning_rate=0.1, l2_lambda=0.01):\n",
    "#     model = Sequential()\n",
    "#     # model = keras.models.Sequential()\n",
    "#     for filters, kernel_size in conv_layers:\n",
    "#         model.add(Conv2D(filters, kernel_size, activation='relu', padding='same', kernel_regularizer=l2(l2_lambda), input_shape=(32, 32, 1)))\n",
    "#         model.add(BatchNormalization())\n",
    "#         model.add(MaxPooling2D((2, 2), padding='same'))\n",
    "#     model.add(Flatten())\n",
    "#     for size in dense_layers:\n",
    "#         model.add(Dense(size, activation='relu', kernel_regularizer=l2(l2_lambda)))\n",
    "#         model.add(BatchNormalization())\n",
    "#     model.add(Dense(24, activation='softmax', kernel_regularizer=l2(l2_lambda)))\n",
    "#     model.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#     return model\n",
    "\n",
    "def create_cnn_model_with_regularization(conv_layers, dense_layers, learning_rate=0.1, l2_lambda=0.01):\n",
    "    model = Sequential()\n",
    "    # model = keras.models.Sequential()\n",
    "    for filters, kernel_size in conv_layers:\n",
    "        model.add(Conv2D(filters, kernel_size, activation='relu', input_shape=(32, 32, 1)))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(MaxPooling2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    for size in dense_layers:\n",
    "        model.add(Dense(size, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Dense(24, activation='softmax'))\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_best_model(group_name, model_group, X_train, y_train_enc, batch_size = 30):\n",
    "    # Train and evaluate each  model\n",
    "    model_histories = []\n",
    "    for model in model_group:\n",
    "        print(f'Model for {group_name}: {model}')\n",
    "        set_seed(42)\n",
    "        history = model.fit(\n",
    "            datagen.flow(X_train, y_train_enc, batch_size=batch_size),\n",
    "            steps_per_epoch=len(X_train) // batch_size,\n",
    "            epochs=50,\n",
    "            validation_data=(X_val, y_val_enc),\n",
    "            callbacks=[early_stopping, reduce_lr],\n",
    "            verbose=1\n",
    "        )\n",
    "        val_accuracy = history.history['val_accuracy'][-1]\n",
    "        model_histories.append((val_accuracy, model))\n",
    "\n",
    "    # Determine the best model based on validation accuracy\n",
    "    best_val_accuracy, best_model = max(model_histories, key=lambda item: item[0])\n",
    "\n",
    "    print(f'The best model is: {best_model} with a validation accuracy of: {best_val_accuracy}')\n",
    "    return model_histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define different dense models to experiment with\n",
    "dense_models = [\n",
    "    create_dense_model_with_regularization([512, 256], learning_rate=0.001),\n",
    "    create_dense_model_with_regularization([1024, 512, 256], learning_rate=0.001),\n",
    "    create_dense_model_with_regularization([1024, 512, 256, 128], learning_rate=0.001)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define different CNN models with regularization to experiment with\n",
    "cnn_models = [\n",
    "    create_cnn_model_with_regularization([(32, (3, 3)), (64, (3, 3))], [128],learning_rate=0.001),\n",
    "    create_cnn_model_with_regularization([(32, (3, 3)), (64, (3, 3)), (128, (3, 3))], [256], learning_rate=0.001),\n",
    "    create_cnn_model_with_regularization([(16, (3,3)), (32, (3, 3)), (64, (3, 3))], [512, 128], learning_rate=0.001)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for Dense: <Sequential name=sequential_30, built=True>\n",
      "Epoch 1/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.3090 - loss: 2.6134 - val_accuracy: 0.1949 - val_loss: 3.4303 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138us/step - accuracy: 0.3000 - loss: 2.4191 - val_accuracy: 0.1916 - val_loss: 3.2828 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.3703 - loss: 2.2782 - val_accuracy: 0.0354 - val_loss: 8.6622 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134us/step - accuracy: 0.5000 - loss: 1.9289 - val_accuracy: 0.0404 - val_loss: 7.6514 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.3979 - loss: 2.1798 - val_accuracy: 0.1191 - val_loss: 9.9652 - learning_rate: 0.0010\n",
      "Model for Dense: <Sequential name=sequential_31, built=True>\n",
      "Epoch 1/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.3163 - loss: 2.8460 - val_accuracy: 0.0251 - val_loss: 6.4824 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176us/step - accuracy: 0.3000 - loss: 2.5263 - val_accuracy: 0.0265 - val_loss: 6.5653 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.3496 - loss: 2.4848 - val_accuracy: 0.1149 - val_loss: 4.5131 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 182us/step - accuracy: 0.4333 - loss: 2.3181 - val_accuracy: 0.1269 - val_loss: 4.3566 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.3745 - loss: 2.4262 - val_accuracy: 0.1645 - val_loss: 3.7115 - learning_rate: 0.0010\n",
      "Model for Dense: <Sequential name=sequential_32, built=True>\n",
      "Epoch 1/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.2845 - loss: 3.0905 - val_accuracy: 0.0229 - val_loss: 11.0317 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187us/step - accuracy: 0.2333 - loss: 2.6734 - val_accuracy: 0.0229 - val_loss: 10.6759 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.3204 - loss: 2.6897 - val_accuracy: 0.1026 - val_loss: 5.2717 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 194us/step - accuracy: 0.2000 - loss: 2.7305 - val_accuracy: 0.1168 - val_loss: 4.8158 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.3475 - loss: 2.5429 - val_accuracy: 0.1760 - val_loss: 3.4393 - learning_rate: 0.0010\n",
      "The best model is: <Sequential name=sequential_32, built=True> with a validation accuracy of: 0.17596207559108734\n"
     ]
    }
   ],
   "source": [
    "dense_histories = return_best_model(\"Dense\", dense_models, X_train, y_train_enc, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model for CNN: <Sequential name=sequential_53, built=True>\n",
      "Epoch 1/50\n",
      "\u001b[1m 24/915\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.1450 - loss: 3.3218 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\linhn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.5425 - loss: 1.5434 - val_accuracy: 0.7025 - val_loss: 0.8218 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m  1/915\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.9333 - loss: 0.3225"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\linhn\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 248us/step - accuracy: 0.9333 - loss: 0.3225 - val_accuracy: 0.6893 - val_loss: 0.8606 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9023 - loss: 0.3204 - val_accuracy: 0.8971 - val_loss: 0.3367 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231us/step - accuracy: 0.9667 - loss: 0.1247 - val_accuracy: 0.8848 - val_loss: 0.3885 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - accuracy: 0.9434 - loss: 0.1793 - val_accuracy: 0.8452 - val_loss: 0.4693 - learning_rate: 0.0010\n",
      "Model for CNN: <Sequential name=sequential_54, built=True>\n",
      "Epoch 1/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.5826 - loss: 1.3916 - val_accuracy: 0.8639 - val_loss: 0.3766 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 301us/step - accuracy: 0.9000 - loss: 0.3133 - val_accuracy: 0.8648 - val_loss: 0.3801 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.9345 - loss: 0.2052 - val_accuracy: 0.9155 - val_loss: 0.2420 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266us/step - accuracy: 1.0000 - loss: 0.0615 - val_accuracy: 0.9041 - val_loss: 0.2772 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.9630 - loss: 0.1171 - val_accuracy: 0.8335 - val_loss: 0.5495 - learning_rate: 0.0010\n",
      "Model for CNN: <Sequential name=sequential_55, built=True>\n",
      "Epoch 1/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - accuracy: 0.4983 - loss: 1.6614 - val_accuracy: 0.8265 - val_loss: 0.4890 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 246us/step - accuracy: 0.9667 - loss: 0.2392 - val_accuracy: 0.8215 - val_loss: 0.5065 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8789 - loss: 0.3662 - val_accuracy: 0.7588 - val_loss: 0.6771 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 241us/step - accuracy: 1.0000 - loss: 0.0583 - val_accuracy: 0.7356 - val_loss: 0.7594 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m915/915\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.9498 - loss: 0.1608 - val_accuracy: 0.9936 - val_loss: 0.0500 - learning_rate: 2.0000e-04\n",
      "The best model is: <Sequential name=sequential_55, built=True> with a validation accuracy of: 0.9935861825942993\n"
     ]
    }
   ],
   "source": [
    "cnn_histories = return_best_model(\"CNN\", cnn_models, X_train, y_train_enc, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: <Sequential name=sequential_55, built=True> - Final Test Accuracy: 0.8337981104850769\n"
     ]
    }
   ],
   "source": [
    "# Combine all histories and models\n",
    "all_histories = dense_histories + cnn_histories\n",
    "\n",
    "# Select the best model based on validation accuracy\n",
    "best_model = max(all_histories, key=lambda x: x[0])[1]\n",
    "\n",
    "\n",
    "# Evaluate the best model on the final test set\n",
    "final_eval = best_model.evaluate(X_final_test, y_final_test_enc, verbose=0)\n",
    "print(f\"Best Model: {best_model} - Final Test Accuracy: {final_eval[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 - 0s - 2ms/step - accuracy: 0.8338 - loss: 0.4865\n",
      "CNN Model - Test Accuracy: 0.8337981104850769\n",
      "\u001b[1m113/113\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Unbiased Median Accuracy: 0.8873002523128679\n",
      "Letter with Highest Accuracy: P\n",
      "Letter with Lowest Accuracy: T\n",
      "Most Common Errors: [('T', 'Q'), ('H', 'G'), ('B', 'J')]\n",
      "Overall Mean Accuracy: 0.8388155483563996\n",
      "Letter A: Accuracy 0.9333333333333333\n",
      "Letter B: Accuracy 0.7314814814814815\n",
      "Letter C: Accuracy 0.832258064516129\n",
      "Letter D: Accuracy 0.8617886178861789\n",
      "Letter E: Accuracy 0.9357429718875502\n",
      "Letter F: Accuracy 0.991869918699187\n",
      "Letter G: Accuracy 0.9425287356321839\n",
      "Letter H: Accuracy 0.8302752293577982\n",
      "Letter I: Accuracy 0.8680555555555556\n",
      "Letter K: Accuracy 0.7818181818181819\n",
      "Letter L: Accuracy 0.9619047619047619\n",
      "Letter M: Accuracy 0.7157360406091371\n",
      "Letter N: Accuracy 0.8972602739726028\n",
      "Letter O: Accuracy 0.8780487804878049\n",
      "Letter P: Accuracy 0.896551724137931\n",
      "Letter Q: Accuracy 1.0\n",
      "Letter R: Accuracy 0.9444444444444444\n",
      "Letter S: Accuracy 0.7804878048780488\n",
      "Letter T: Accuracy 0.6935483870967742\n",
      "Letter U: Accuracy 0.05263157894736842\n",
      "Letter V: Accuracy 0.7803468208092486\n",
      "Letter W: Accuracy 0.9223300970873787\n",
      "Letter X: Accuracy 0.9774436090225563\n",
      "Letter Y: Accuracy 0.9216867469879518\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(\"CNN\", best_model, X_final_test, y_final_test_enc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
